 Today we will talk about Case-Based Reasoning. In Case-based reasoning, the cognitive agent addresses new problems by tweaking solutions to similar previously encountered problems. Case-based reasoning builds on the previous lesson on learning recording cases. In learning recording cases, the new problem is identical to the previous problem. In case-based reasoning, the new problem is similar to a previously encountered problem. Case-based reasoning typically has several phases, case retrieval, case adaptation, case evaluation, and case storage. We'll also discuss certain advanced processes of case-based reasoning which will include new methods for case retrieval.
 To illustrate the difference between case-based reasoning and learning by recording cases, or instance-based learning, let's revisit our micro-world of blocks. Once again, you can see all of these blocks in this micro-world. So you can see the colors, you can see the shapes, and you could even touch them, so you have some idea about their approximate sizes. Now let us suppose I give you a new block. Note that this new block, the size, is very different from the size of any of the other blocks. What color do you think this block will be?
 >> And that's the point. The point being that often, the new problem is not identical to the old problem. And when it's not identical, then we have to do some reasoning. We can not just retrieve something from memory, and use the same solution that was used earlier. Case-based reasoning, the phrase case-based reasoning, has two parts to it, case-based, and reasoning. So far we have looked at the case-based part, where we can just extract something from memory and reuse it. Now we can look at the reasoning part. Once you have extracted something off memory, how can you reason about it, and adapt it, but for the new problem?
 To examine a more realistic problem, let's revisit the problem that we had in our last lesson. Once again, this is a map of a part of Long Island, and the problem is to go from Q to the end location here. So I'll call it Q problem. We'll retrieve from memory the D case, which takes us from this initial location to this collocation. Clearly, this D case is potentially useful for addressing the Q problem. But it is not useful as is. The initial location of the D case is not the same as the initial location of the Q problem. And the end location of the D case is not the same as the end location of the Q problem. So we can start with this D case but we need to adapt it. So, this leads us to the overall process of case-based reasoning. The basic process of case-based reasoning consists of four steps. The first step is retrieval, and we already and considered this when we were considering learning by recording cases. K nearest neighbor is one way of retrieving cases from memory. Once we have retrieved a case from memory that is delivered to the current problem, we need to adapt it. For example, in the previous problem we had the D case and the Q problem. And we needed to adapt the D case into the Q problem. There are many similar examples. All of us program and all of us, as computer programmers, sometimes use case-based reasoning. We are given a new problem to address, and we often look at the design of a program that we have come across earlier. So there's retrieving a case and they're adapting a particular design of the old program to solve the new problem. Once we have adapted the case to meet the requirements of the new problem, we have a candidate solution for the new problem. With it, the candidate solution is to be evaluated. For example, in the navigation problem, when we have a solution of the Q problem, we can evaluate it but they would actually take us to the end location. We can do a simulation, we can walk through it. As we walk thought it, we will be able to evaluate whether the solution actually succeeds in meeting the requirements of the problem. For the programming problem, once we have a new program that we obtain by adapting the old program, we can actually run the program to see, whether or not it will meet the requirements of the new problem. Let us suppose for a moment that we evaluate a candidate solution and it succeeds. Then, we could encapsulate the new problem and the new solution into a case, and store it back into the case memory, so that case memory is constantly increasing. Notice that this case-based reasoning process unifies memory, reasoning, and learning. There is a case memory that contains a large number of cases and that's how we retrieve cases that are relevant to the current problem. We'll reason when we adapt and evaluate. And we learn when we store the new case back into the case memory.
 So like any other theory of intelligence, case-based reasoning has some assumptions. The first assumption is that there are patterns to the problems that agents encounter in the world. The same kinds of problem tend to reoccur, again and again. A lot of science is about finding patterns that are crowded in the world. Physics finds patterns that are crowded in the world that are expressed by various kinds of laws, like Newton's second law of motion. Presumably, if you're going to build a theory of intelligence, that theory too will give an account of what kind of patterns exist in the world that mind, that intelligence, must encounter. And case-based reasoning says, one of the common patterns is that the same kinds of problems occur again, and again, and again. So that's the first assumption. The second assumption is that similar problems often have similar solutions. Here is a grid of a part of Long Island. Here is a grid of part of Dallas, Texas. Now if you look at the one in Long Island, you can see that if there are two problems which are very close to each other, they're likely to have very similar solutions. And the same is true for the grid in Dallas. Similarly, the second assumption is not always valid. Here is an example of it. I'm sure all of you know how to tie your shoelaces. But imagine that you buy a new pair of shoes, and this new pair of shoes have velcro straps. Now the problem's very similar, how to tighten your shoes, but the solution is radically different. >> So Ashoke, another example of this that comes to mind, for me, is the example of touch screens. Some of the early touch screens could only handle one touch at a time. If you touched it with two fingers at a time, it either wouldn't register, or it'd only register one of the touches. Current touchscreens, on smartphones and tablets that we use today, can handle two or three or four fingers at a time. The problem is very similar. We're still touching the screen and interacting with it with our fingers, but the solution is actually very, very different. It uses a completely different kind of technology, different material for the screen, and a different way of detecting where the screen is being touched. >> That's a good example, David. So we have at least two examples now where similar problems can have quite different solutions. Nevertheless, this assumption is valid most of the time. Most of the time, two problems that are quite similar will end up having two solutions that are quite similar, as well.
 Let us look at adaptation a little bit more deeply. So once again here is the process of case-based reasoning. I have kind of blurred the retrieval step. We're going to assume here that the retrieval of the case has already occurred, perhaps using the KNN method that we discussed last time. Last time we also said two other things. One, that a fundamental conundrum that AR agent faces that the problems they encounter are usually very complex from a computational perspective. And they have only limited calculative resources. So then how can they address computationally complex problems, with limited calculative resources, in near real-time? Seemingly effortlessly. And we said part of the answer might be that memory supplies with an answer. But we are going to make a small amendment to it. Memory supplies with an answer, an almost correct answe,r so that the adaptation that we have to do is very small, very minor. It's a tweak. As an example of adaptation being mostly tweaking, consider this simple problem, the everyday problem of cooking meals. So you may have a recipe for your favorite kind of meal. And imagine at this time you're going to have your favorite meal, perhaps with different company, or perhaps with a different kind of salad or appetizer. Well in that case you might tweak your recipe for that particular dish. You're not going to change it in a radical way, you're simply making a small change to it. >> So, Ashoke, another example of this that comes to mind very readily for me, goes back to your programming example from earlier in this lesson. One thing that almost every program I write has to do is input data from a file. But right now, I couldn't write that process from scratch. What I always do is I look at however I did it the previous time, and I'll modify it for the new folder or the new kind of data or the new kind of file I'm reading from. But really I'm just taking the same process and tweaking it for my new problem. >> That's a good point, David. In fact in the design commonly there's an old cliche, which says that all designers redesign. Design is fundamentally evolutionary, we take all designs and we evolve them slightly and that's how we get a new design. And the same thing is happening in case-based reasoning here. It is saying that often this particular solutions that we come up with are revolutionary in the nature in the sense that they are small tweaks over previous solutions. So the next question becomes, how can we adapt an old case to meet the requirements of new problem? There are potentially several ways of doing it. We will discuss three important ways, perhaps the three most common ways of adapting a case. They are called the model-based method, the recursive case-based method, and the rule-based method.
 Let us look at the first, the model base method for adapting our case. Once again we're in this micro world. Let us suppose that we begin from our office, and we need to go to a restaurant. Given the problem of going from the office to the restaurant, let us suppose that we retrieve from memory a case that takes us to a doctor's office, which is quite close to the restaurant but not the same as the restaurant. So one way in which I might be able to allot this case that I have received to address the problem going from the office to the restaurant, is to do a search using this model, this map of the world, which tells me that to go from the doctor's office to the restaurant office, you can take this particular route. So now, I have the earlier case, which I've adapted, using some model of the world. This is an example of using models In order to adapt cases. >> So in my programming example earlier, instead of having a map of the world, we might have for example an API for interacting with a particular language. I've done input from a file in Python several hundred times, but I've never done it in Java before. I know that the overall process of doing in from Java is going to be very similar to the process of doing it in Python. And I have a model of the way Java works, to know how to actually translate my case of doing in it in Python to doing it in Java. >> Good example David. It is another one. This one is from design. When we design with this kind of product, let's suppose a VLSI circuit for example, than we not only know something about the configuration of the elements in the design, we also have a model of how that particular configuration is supposed to work. In fact, it might amuse you, David, that about 25 years back in the 80s, when I wrote my PhD dissertation, it was one of the first PhD dissertations that integrated model-based spacing and case-based spacing. That was exactly the idea in my PhD dissertation. You used models to be able to adapt, evaluate, and store cases.
 A second method to adapt cases is to use case based reasoning recursively. So last time we considered problem which I had to go from my office to a restaurant, and I found a way of doing that. Now suppose that I have to go from my home to the same restaurant. So I don't yet know how to go from my home to the restaurant, but I know how to go from my home to my office. And this last time, I figured out a way of going from office to the restaurant. So there we have it. Now I have a case retrieved for going from home to office, another case retrieved for going from office to the restaurant, and I have a solution. We're going from home all the way to the restaurant. This is an example of case based reasoning. Your first time you retrieve a case for solving a problem, the case provides a partial solution. So I take the remaining part which was not solved, make it a new problem, and send it back into the case memory. Now the case memory finds me a new case. And I take this new case and I compose it with the previous case to get a full solution. >> So to return again to our programming example, when I'm designing a program, my file input is usually part of a broader problem of persisting data between instances of the program. And thus, the real problem I'm solving is solving this problem of how to save data when the program isn't running. I can then solve that problem recursively by breaking it down into the first problem of file input and the second problem of file output. I might draw a case for solving file input from one program I've done in the past and a case for solving file output from another program in the past. So I've solved it recursively by breaking it down into sub problems. >> David, to build on what you just said, the same kind of thing occurs in design in general. Often when we do design, we get partial solutions for multiple cases. For example, consider the problem of designing a microbot that can swim underwater in a very stealthy manner. This might remind me of a case of a copepod which has large number of appendages and swims in the water at very slow velocity making minimum wake in the water. That's good, I've now solved part of the problem, the part which had to do with moving stealthily underwater under slow speeds. But that now sets up a new goal, how do I achieve stealthy motion underwater at high speeds? And I may come up with a solution from a different case. So a squid, for example, also swims stealthily underwater, but it does so by creating a wake that matches the natural wake of water around it. So here I first used the goal of designing a microbot that can swim underwater stealthily to retrieve a case of the copepod. That provide me with a partial solution. So I set up a new sub-goal to complete the solution. The new sub-goal found a new case, that of the squid, which gave me the rest of the solution. And if I compose the two partial solutions, I get the complete solution. >> So what Ashok just described is something that we call compound analogy, which is a specific type of adaptation by recursive reasoning. If you're interested in that example, we've provided a paper on it in the course materials for this lesson. So you can read more about the process of adapting those cases to solve that very unique and complex design problem.
 Let us now consider a third method for adapting cases. This method uses heuristics expressed in the form of rules. A heuristic is a rule of thumb. Let's take an example. Imagine that you went to a new city, and you wanted to find out where the downtown was. How could you do that? A simple heuristic is that you just look around and you find where the tallest buildings are. At least in North America, the tallest buildings tend to be in the center, in the downtown of the city. And this heuristic doesn't work all the time. Outside North America, this heuristic sometimes fails. And that's the point. A heuristic is a rule of thumb that works often, but not always. To see how the heuristic method works for adapting cases, consider our problem. Imagine that we're at a restaurant and we need to go back home. Recall that we just found a solution for going from the home to the restaurant. Having found that solution, having evaluated it and executed it, we stored it as a case in memory. So now when we have to go back from the restaurant to the home, we can retrieve that previous case of going from home to the restaurant. Given a new problem and a case, how do we adapt the case to achieve the new problem? In this case, we may have a heuristic which says that to go back from where you came originally, you simple have to flip back all the terms. This might give us a solution that is shown here. Note that this heuristic may not always work. It's a rule of thumb. It works often, but of course, we know that we cannot reverse all the turns all the time. >> So to return to our programming example, we were doing file input, and file input is often a very resource intensive process. So let's say I'm designing a new program and for this new program, efficiency is a much bigger concern. I might have a rule that says when doing file input, it's more efficient to read entire arrays of data at a time instead of just reading one byte at a time. The previous case that I'm adapting might have had file input as 1 byte at a time. But I'm going to use that rule to adapt the case to read arrays of data at a time. So, in that way, that rule has helped me design a file input method that's more efficient. >> David, to generalize on your answer to design. >> Designers often use heuristics of the kind that you mentioned. For example, if you want to make an artifact lighter, try a different material. It's a heuristic expressed as a rule.
 So let us return to our overall process for case based reasoning. We have looked at adaptation a little bit. Let's not look at evaluation. The adaptation step has not given us a candidate solution. The evaluation step is concerned with how to assess the suitability of the candidate solution to the problem at hand. So one method of doing evaluation of a case based solution is through simulation. Consider the problem going from the home to the restaurant. Case based reasoning proposed a candidate solution. In order to find out whether this solution actually works, I can do a simulation. I can even do an execution in the [INAUDIBLE]. In this case, we might find out if solution actually works. And we might accept the solution. Now, consider an alternative problem. This time, we have to go from the restaurant to the home, and we decided we would simply flip all the turns. But as we execute the solution, we find out that some of the turns are only one way. Now this particular solution fails. In this particular domain, the cost of executing a solution may be low, therefore we can just go ahead and execute it. In other domains, the cost of execution may in fact be quite high and the best we can do is to first simulate it before we decide to execute it. >> So evaluation is built very closely into our programming example. Every time we run a program and see whether or not it worked, we're in fact evaluating whether or not our adaptation successfully solved our new problem. When it didn't, we return to the adaptation phase and we try again or we might return to the retrieval phase, and retrieve another case to use to inform our solution. >> In design more generally, we can simulate the design, or we can actually prototype a design. Under the matter for evaluating a design could be to share it with other designers and let them critique it. So there are a number of different methods that are possible for evaluation as well.
 So we just talked about how the evolution step in the case based reasoning process when decided a correct solution in fact meets the requirements of the given problem. Now that we have the new problem and the solution for it, we can encapsulate them as a case, and store them in a case memory. We saw the advantages of this kind of storage earlier, when we went from home to restaurant. We stored that case is memory so that when wanted to go back from restaurant to home. We could retrieve that case and try to adapt it. So case choice is an important way of learning. We are constantly accumulating and assimilating new cases. We talk about two kinds of storage mechanisms. Indexing and discrimination crease.
 >> The rest of the notion of indexing, let's go back to our navigation world. Imagine that we already have cases A, B, C and D. We might use a very simple indexing scheme to begin with. We might say well simply index each case with its initial location and the initial location will have a X coordinate and a Y coordinate. So the case A may be indexed by its initial location, which is 3E and 9N and similarly for B, C and D. Now imagine that we have a new case, X of going from the office to the restaurant. Recall that we're indexing cases right now very simply by the XY coordinates of the initial location. So in index case X by the XY coordinates of the initial location here. Let me repeat, this is really a very simple indexical scheme we are using here. As we learned in the lesson last time, we really should be using a more complicated indexical scheme, which takes into account both the initial location and final locations. Nevertheless, this can raise the basic notion of an index. An index is like a tag. At least in principle, we could come up with which index equals key for this particular class of problems? We don't have to limit our social suggesting numerical coordinates of the initial and the goal locations. For example, in this navigation MicroWorld, the indexes may include whether they are scenic or not scenic, whether their route is fast or not fast. >> So going back to our programming example we were working with file input and we could have a very rich indexical structure for organizing cases of file input according to various different parameters and variables. For example, I might tag the individual cases of file input according to whether I use Java, Python, C++. I might tag them according to whether there were very fast or very slow and I tagged them according to what kind of file they read in. Did they read text? Did they read XML? Did they read some other kind of file format? Each of those value then becomes a particular way of identifying each individual case, such that when I'm given a new problem, I can find the most similar case by seeing which one matches the most of those variables. >> That's an important point. We want to use an indexical structure, which allows for effective and efficient retrieval, because we are storing things only, because we want to retrieve them at a later time. In case of design more generally, people have developed indexical structures that have to do with functions, with operating environment, with performance criteria and so on.
 But for now, let's go back to where, original navigation micro world. Imagine that we have a nucleus Y. Given our index equals scheme here, of X were coordinates of the initial location, what do you think of the indices of the case Y?
 Hey Rick, what's your answer? >> So we can see pretty easily that Y aligns with 1 E, in the horizontal direction, and approximately 9 N in the vertical direction. So, it's 1 E and 9 N. >> Precisely.
 Let's consider a different case. Supposing we have a case Z of going back from the restaurant or the home. Let's also suppose that we're change our index equal Kim. Now we are indexing things by the x square coordinates of the destination not the origin. What will be the indices for the case Z?
 >> That's a good point David. Remember that we're trying to store things, because we want to retrieve things later. And if our storage mechanism is such that it doesn't not allow for efficient retrieval, then it's not a very good storage mechanism. And as you correctly point out, David, as the number of entries increase in this table, and the number of dimensions we are looking at increase also increases. This is going to be coming an inefficient for retrieval. Therefore, let's look at a second method called discrimination trees which provides an alternate way of storing these cases in memory.
 A discrimination tree is a knowledge structure, in which the cases themselves are the leaf nodes of the tree. At the root node, and at all the intimated nodes are questions. The questions of the root node and the intimidated node pertain to the pertain to the indexical structures of the cases. So recall that, we were using the origins of the cases as the index equal structure. Let's stay with that point just a while longer. So now I might have a question that the root node which says is the origin not of 5N? If the answer to that question is yes, then it brings us to this branch. If the answer is no, it takes us to the other branch. At this node I might ask, is the origin east of 5 of E? If yes, it brings us to this branch. If no, it brings us to that branch. In this way we are able to discriminate between C and A, in fact we able to disconnect with C not all of the cases. Similarly for this part of the graph. So now that we have learned, what is the knowledge structure discrimination trees for organization the case memory, let us now look at how will we store a new case. How will we incrementally learn this knowledge structure as new cases are put into the case library? Imagine that there is a new case, X. So we can navigate this tree using X. Is the origin of X North of 5 of A? Yes it is. So we come to this branch. Is the origin of X East of 5 of E? No it is not, so we come to this branch. But now we have a problem. Both A and X, have the same answer no to this question. We must find a way of discriminating between A and X, so we'll add a new question here. Perhaps we can add a new question. Is the origin East of 3 of E? In the case of X, the answer is yes. In the case of A, the answer is no. That's why adding a right node at the right place, we have found a way of discriminating between X and A. This now is a modified discrimination tree. Each time we add a location to memory, the organization of the case of memory changes. This is an example of incremental learning, with the addition of each case some new knowledge structure is learned. We learn more about incremental learning in the next lesson. >> So going back to our programming example, we were dealing with cases of file input, and we could use the same indexical structure according to which we organize our cases to now design a discrimination tree. At the very top level I would probably ask, what language is the casing? Is it in Java, C++, Python? Now the discrimination trees don't have to be binary like they are right here. We can have more than two answers coming out. So at the top level, I could have a question of what language is the case in, and the branches could be JAVA, C++, and Python, and so on. I could similarly have questions about, is it an efficient solution, is it for a big problem or a small problem, is it for my personal use or is it for consumer use, and so on until I get down to individual cases that represent different things I might want to consider when I'm doing a new solution. >> David a point you make about this not being a but a very important one. Let's go back to our original example, where we had a micro world of blocks and the blocks had different colors. So I can ask a question at the root node, what is the color of the block? And have a large number of branches coming out of it corresponding to different colors. Here's an example of a discrimination tree, not a binary print.
 Let us do an exercise. Supposing we're given the case Y, as shown here. And we're given the discrimination tree, shown on the left. Where would you store the case Y in this discrimination tree?
 What did you come up with, David? >> So I started at the root, is the origin North of 5N? It certainly is. Is the origin East of 5E? No, it's not. And is the origin East of 3E? No, it's still not. So I said Y would go down here alongside A. That's good, David, but of course, we must find a way of discriminating between A and Y.
 But know that A and Y were in this same branch. So we now we need to find a way of discriminating between A and Y. How could we do that?
 What did you find, David? >> So we've got A right here and Y right here. We've got a line that goes through the two that differentiates them that roughly lines up with 2E. So I said 2E. >> That looks like a good answer to me. Recall that when we were using the table to organize the case memory previously, we were very concerned that this side of the table would grow very large. It will become very difficult to search for a specific case in that table. The potential answer to that. By asking a question we are quickly able to prune away one part of the tree. That makes this search process much more efficient. And that's the point of the discrimination tree. In both organizational scheme, the table and the discrimination tree, we are trying to accommodate and accumulate new cases. But in the case of the discrimination tree, by asking the right questions to the right nodes, we make the search process more efficient. >> So for those of you familiar with big O notation, you'll notice that the efficiency of searching the case library organized by indices was linear, whereas here it's logarithmic.
 Now that we have considered storage, let's revisit retrieval. We talked about two different ways of organizing the case memory, a tabular way and a discrimination tree. How can we retrieve the case relevant to a given problem? We assume here that the new problem has the same features in its description as the cases stored in the memory. Earlier when we were storing a case in memory, at that time we were navigating this tree to find where in this tree should we store the new case. This time, we'll use the problem to navigate this tree and find out which case is most similar to the problem.
 Let us suppose that the case library is organized in the form of a table as shown here. Let us also suppose that we're given a new problem, how to go from this initial location to this goal location. Which case should be retrieved?
 So what was your answer, David? >> So comparing the X coordinate of the various cases I found that there's two cases that match the X coordinate of the new problem, A and C. Comparing the Y coordinates, though, A is all the way up here, so I would choose C which matches the X and the Y coordinate exactly. >> That's right, David.
 Let's repeat this exercise, but this time using discrimination tree for organizing the case memory. So here is a discrimination tree, containing the cases currently in the case memory. And here is the, new problem. You could go to the initial location, to the goal location. Given this problem, what case would be retrieved from this discrimination tree?
 David what was your answer? >> So this time we're looking at the origin instead of the destination. We start at the route and ask, is the origin north of 5N? Just barely it is. Is it East of 5E? No, is it east of 3E? No, is it east of 2E? It's really not east of anything. So the case we retrieve is going to be Y. >> Thatâ€™s right David. Y is the closest matching case to the new problem.
 So far we have talked about the very basic process of case based reasoning and we have portrayed as if this process was linear. But of course the case based reasoning process may not necessarily be linear. As an example, if the evaluation fails, then we might want to adapt that particular case in a different way. As an example of the evaluation of the candidate solution, that adaptation had produced fails. Then, instead of abandoning that particular case, you might want to try to adapt it again. Alternatively, if we try to adapt the same case several times, but we just cannot adapt it, we might want to abandon that case and try to find a different case from the case memory. There is another possibility. Suppose that we retrieve a case from memory. And we try to adapt it but we are unable to adapt it to meet the requirements of the new problem. In that case, you might want to abandon the case and try to do a new one. There is yet another possibility. Let us suppose that we retrieve a case from memory and it exactly matches the new problem. In that case, no adaptation needs to be done and we can jump down to evaluation. In fact this is what happened when we're discussing the KNN method. In this way we can see that there are many ways in which this process need not necessarily be linear. >> So Ashok, earlier you said that if the evaluation shows that the new solution is good, then we should store it. If the evaluation shows that the new solution is not good, we should try adapting again or we should try retrieving again. But what about evaluation showing that new solution is not good? Should we ever store those? >> Indeed, sometimes studying failed cases is also very useful. Failed cases can help us anticipate problems. So imagine if you're given a new problem, and you retrieve from your case memory a failed case. That failed case can be very useful because it can help you anticipate the kinds of problems that will occur in solving the new problem. >> So that reminds me of another example from our file input problem. One thing I've encountered a lot when I'm doing a file input is that if you read too far in the file, then the program will crash and it'll give you an error. It will always give you the same error, and it's a very common problem because different languages do file input slightly differently. So in my mind, I must have cases of the different ways that it's failed in the past, so I can anticipate those and do it correctly in the future. >> Failures are great opportunities for learning. When failures occur, we can try to repair the failure by going back from the evaluation step to the adaptation step. Or we can try to recover from the failure by going from the evaluation step all the way to the retrieval step. In addition, we can store these failures in the case memory. When we store them in the case memory, then these failures can help us anticipate failures that might occur with new problems. There's a flip side to this. Just like it is useful to store failed cases, it is not useful to store every successful case. If we stored every successful case, then very soon the case memory will become very, very large, and the retrieval step will become less efficient. This is sometimes called the utility problem. We want to store only those successful cases that in fact help us cover a larger span of problems. This means that, even when a case succeeds, we want to store it only if there is something interesting or noteworthy about that case.
 In this assignment, discuss how you'd use case-based reasoning to develop an agent that can answer Raven's Progressive Matrices. Make sure to describe how this is different from learning by recording cases alone. Where is your adaptation phase? How are you adapting past solutions to the new problem? What is evaluation in this context? How are you evaluating the strength of your answer? Are you going to record the cases that your agent encounters as they're solving the test, or are you going to equip them with past cases beforehand for them to use to solve new problems?
 So today we talked about the broad process of case-based reasoning. Learning by recording cases gave us a method for case retrieval called nearest neighbor method. So we went ahead and jumped into the adaptation phase. Given an old solution to a problem, how do we adapt that old solution to a new problem? We talked about three ways of doing that. We can do it by model of the world, we can do it by rules, or we can do it by recursion. Then once we've adapted that old case, how do we then evaluate how good it was for our problem? Then after we evaluated how good it is we looked at storing it back in our memory. We want to build up a case library of past solutions, so if we've solved a new problem we will now sort that back into our case library. Then based on that we revisited the notion of case retrieval. Based on how our case library is organized, how do we retrieve a prior case that's most similar to our new problem? Now there are a lot of open issues here. For example, should we store failed cases? Should we store failed adaptations? Do we want to store them so we can avoid failing in the future? Should we ever forget cases? Can our case library ever get so big that it's intractable, and we can't really use it efficiently? Should we abstract over cases, so should we use these individual cases to develop a more abstract understanding of a concept, or should we stick the individual cases and adapt them from there? If you're interested in these questions you can over to our forums and we'll talk about it there. But we'll also be revisiting these questions throughout the rest of the course. Next time we'll talk about incremental concept learning, which takes individual cases and abstracts over them to learn some kind of higher level concepts.
 Caseless reasoning has a very strong connection with human cognition as well. Analogical reasoning in general is considered to be a core process of cognition. But analogical reasoning depends upon a spectrum of similarity. At oned end of this spectrum are problems which are identical to previously encountered problems. In that case, we simply have to retrieve the previous solution and apply it. At the other end of the spectrum, are problems with just semantically very dissimilar from previously encountered problems. We'll discuss those problems later in the class. In the middle of the spectrum are problems. Which are similar, but not identical, to previously encountered parts. So now, we need to retrieve the past solutions, tweak them, and apply them. It is this middle of the spectrum, which is most common in human cognition. Again, going back over cognitive architecture, which had 3 components. Reasoning, learning, and memory. Learning by recording cases shifted the balance from reasoning to learning and memory. Case we can contrast unifies the three of them. It says learning is important because we need to acquire and store experiences. Memory is important because we need to be able to retrieve those experiences when needed. And reasoning is important because we need to be able to tweak those experiences to encounter the needs of new problems.
 Please write down what you learned in this lesson.
 And thank you for doing it.
